{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-05T05:15:10.422501Z","iopub.status.busy":"2024-04-05T05:15:10.422087Z","iopub.status.idle":"2024-04-05T05:15:57.225315Z","shell.execute_reply":"2024-04-05T05:15:57.224195Z","shell.execute_reply.started":"2024-04-05T05:15:10.422467Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import timm\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import random\n","\n","seed = 2024\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load CIFAR-10 dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","\n","# Split the training set into a subset of 40 samples and the rest\n","subset_size = 400\n","remaining_size = len(trainset) - subset_size\n","subset_trainset, remaining_trainset = random_split(trainset, [subset_size, remaining_size])\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Create data loaders\n","trainloader = DataLoader(subset_trainset, batch_size=4, shuffle=True, num_workers=2)\n","testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","# Load the ResNet model from timm\n","model = timm.create_model('resnet101', pretrained=False, num_classes=10)\n","model = model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 200 == 199:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 200))\n","            running_loss = 0.0\n","\n","print('Finished Training')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-05T05:15:57.227589Z","iopub.status.busy":"2024-04-05T05:15:57.227277Z","iopub.status.idle":"2024-04-05T05:16:42.347080Z","shell.execute_reply":"2024-04-05T05:16:42.346026Z","shell.execute_reply.started":"2024-04-05T05:15:57.227559Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score\n","# Test the model\n","correct = 0\n","total = 0\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data[0].to(device), data[1].to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        y_true.extend(labels.cpu().numpy())\n","        y_pred.extend(predicted.cpu().numpy())\n","\n","accuracy = correct / total\n","f1 = f1_score(y_true, y_pred, average='macro')\n","\n","# print('Accuracy: %.4f' % accuracy)\n","# print('F1: %.4f' % f1)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.status.busy":"2024-04-06T14:56:40.337212Z","iopub.status.idle":"2024-04-06T14:56:40.337572Z","shell.execute_reply":"2024-04-06T14:56:40.337423Z","shell.execute_reply.started":"2024-04-06T14:56:40.337401Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","100%|██████████| 170498071/170498071 [00:15<00:00, 11218817.58it/s]\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Training resnet18...\n","Finished Training\n","resnet18 Accuracy: 0.262\n","resnet18 F1: 0.2424 \n","\n","Training resnet34...\n","Finished Training\n","resnet34 Accuracy: 0.3796\n","resnet34 F1: 0.2538\n","\n","Training resnet50...\n","Finished Training\n","resnet50 Accuracy: 0.4336\n","resnet50 F1: 0.4267\n","\n","Training resnet101...\n","Finished Training\n","resnet101 Accuracy: 0.4462\n","resnet101 F1: 0.4354 \n","\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import timm\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import random\n","from sklearn.metrics import f1_score\n","\n","seed = 2024\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load CIFAR-10 dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","\n","# Split the training set into a subset of 40 samples and the rest\n","subset_size = 400\n","remaining_size = len(trainset) - subset_size\n","subset_trainset, remaining_trainset = random_split(trainset, [subset_size, remaining_size])\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Create data loaders\n","trainloader = DataLoader(subset_trainset, batch_size=4, shuffle=True, num_workers=2)\n","testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","# Define loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train and evaluate models\n","models = ['resnet18', 'resnet34', 'resnet50', 'resnet101']\n","for model_name in models:\n","    print(f'Training {model_name}...')\n","    model = timm.create_model(model_name, pretrained=False, num_classes=10)\n","    model = model.to(device)\n","\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    # Train the model\n","    num_epochs = 50\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            if i % 200 == 199:\n","                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}')\n","                running_loss = 0.0\n","\n","    print('Finished Training')\n","\n","    # Test the model\n","    correct = 0\n","    total = 0\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","    accuracy = correct / total\n","    f1 = f1_score(y_true, y_pred, average='macro')\n","    print(f'{model_name} Accuracy: {accuracy:.4f}')\n","    print(f'{model_name} F1: {f1:.4f}')\n","    print()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","100%|██████████| 170498071/170498071 [00:15<00:00, 11218817.58it/s]\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","Training resnet18...\n","Finished Training\n","resnet18 Accuracy: 0.2852\n","resnet18 F1: 0.2674\n","\n","Training resnet34...\n","Finished Training\n","resnet34 Accuracy: 0.3719\n","resnet34 F1: 0.2838 \n","\n","Training resnet50...\n","Finished Training\n","resnet50 Accuracy: 0.4881\n","resnet50 F1: 0.4794\n","\n","Training resnet101...\n","Finished Training\n","resnet101 Accuracy: 0.4783\n","resnet101 F1: 0.4531 \n","\n"]}],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import timm\n","from torch.utils.data import Subset\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import random\n","from sklearn.metrics import f1_score\n","\n","seed = 2024\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define transformations\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load CIFAR-10 dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the training set into 40 samples per class\n","subset_indices = []\n","for class_idx in range(10):\n","    class_indices = [idx for idx, (_, label) in enumerate(trainset) if label == class_idx]\n","    subset_indices.extend(random.sample(class_indices, 40))\n","\n","subset_trainset = Subset(trainset, subset_indices)\n","\n","# Create data loaders\n","trainloader = DataLoader(subset_trainset, batch_size=4, shuffle=True, num_workers=2)\n","testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","# Define loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","# Train and evaluate models\n","models = ['resnet18', 'resnet34', 'resnet50', 'resnet101']\n","for model_name in models:\n","    print(f'Training {model_name}...')\n","    model = timm.create_model(model_name, pretrained=False, num_classes=10)\n","    model = model.to(device)\n","\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","\n","    # Train the model\n","    num_epochs = 25\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data[0].to(device), data[1].to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","            if i % 200 == 199:\n","                print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 200:.3f}')\n","                running_loss = 0.0\n","    print('Finished Training')\n","\n","    # Test the model\n","    correct = 0\n","    total = 0\n","    y_true = []\n","    y_pred = []\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data[0].to(device), data[1].to(device)\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predicted.cpu().numpy())\n","\n","    accuracy = correct / total\n","    f1 = f1_score(y_true, y_pred, average='macro')\n","    print(f'{model_name} Accuracy: {accuracy:.4f}')\n","    print(f'{model_name} F1: {f1:.4f}')\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
